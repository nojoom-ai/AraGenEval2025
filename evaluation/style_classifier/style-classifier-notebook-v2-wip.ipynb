{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12342718,"sourceType":"datasetVersion","datasetId":7780982},{"sourceId":12359253,"sourceType":"datasetVersion","datasetId":7792091},{"sourceId":12396744,"sourceType":"datasetVersion","datasetId":7817404},{"sourceId":12398442,"sourceType":"datasetVersion","datasetId":7818573}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kaggle Setup","metadata":{}},{"cell_type":"code","source":"import os\n\npath = \"/kaggle/working\"\nis_empty = (len(os.listdir(path)) == 1)\n\n# !cp -r /kaggle/input/arageneval2025-task1-sc/* /kaggle/working/\n\nif is_empty:\n    print(f\"✅ '{path}' is empty. copying project strcuture into it ...\")\n    !cp -r /kaggle/input/arageneval2025-task1-sc/* /kaggle/working/\n    # !cp -r /kaggle/input/arageneval2025-task1-dataset/* /kaggle/working/\n    # !mv /kaggle/working/data/data /kaggle/working/data_tmp\n    # !rm -r /kaggle/working/data\n    # !mv /kaggle/working/data_tmp /kaggle/working/data\nelse:\n    print(f\"❌ '{path}' is not empty — contains {len(os.listdir(path))} items.\")\n\n\n\n\n# Change to project directory\n%cd /kaggle/working/ \n\n# Confirm\n!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T09:01:12.631109Z","iopub.execute_input":"2025-07-07T09:01:12.631306Z","iopub.status.idle":"2025-07-07T09:01:12.756640Z","shell.execute_reply.started":"2025-07-07T09:01:12.631290Z","shell.execute_reply":"2025-07-07T09:01:12.755594Z"}},"outputs":[{"name":"stdout","text":"❌ '/kaggle/working' is not empty — contains 12 items.\n/kaggle/working\nconfig.py  evaluation\tmodels\t __pycache__\t  sc_results.zip  utils\ndata\t   __init__.py\tprompts  run_pipeline.py  state.db\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T09:01:12.758259Z","iopub.execute_input":"2025-07-07T09:01:12.758608Z","iopub.status.idle":"2025-07-07T09:01:12.762149Z","shell.execute_reply.started":"2025-07-07T09:01:12.758573Z","shell.execute_reply":"2025-07-07T09:01:12.761441Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# # Navigate to project folder\n# %cd /content/drive/MyDrive/AraGenEval2025\n# !ls","metadata":{"id":"snkePh0ID2ad","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T09:01:12.762973Z","iopub.execute_input":"2025-07-07T09:01:12.763200Z","iopub.status.idle":"2025-07-07T09:01:12.779375Z","shell.execute_reply.started":"2025-07-07T09:01:12.763184Z","shell.execute_reply":"2025-07-07T09:01:12.778689Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Add project root to Python path\nimport os\nimport sys\nsys.path.insert(0, os.getcwd())\nprint(\"✅ Project root added to sys.path:\", os.getcwd())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T09:01:12.781356Z","iopub.execute_input":"2025-07-07T09:01:12.781701Z","iopub.status.idle":"2025-07-07T09:01:12.795014Z","shell.execute_reply.started":"2025-07-07T09:01:12.781673Z","shell.execute_reply":"2025-07-07T09:01:12.794418Z"}},"outputs":[{"name":"stdout","text":"✅ Project root added to sys.path: /kaggle/working\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade transformers==4.41.2 datasets==2.19.1 scikit-learn torch wandb python-dotenv evaluate --quiet\n!pip install -U transformers==4.41.2 peft==0.11.1","metadata":{"id":"ZOea51qwDdX9","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T09:01:12.795739Z","iopub.execute_input":"2025-07-07T09:01:12.795909Z","iopub.status.idle":"2025-07-07T09:04:17.857428Z","shell.execute_reply.started":"2025-07-07T09:01:12.795896Z","shell.execute_reply":"2025-07-07T09:04:17.856681Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nsklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.0 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ntorchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.3.1 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: transformers==4.41.2 in /usr/local/lib/python3.11/dist-packages (4.41.2)\nCollecting peft==0.11.1\n  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (2.32.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (7.0.0)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (2.7.1)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (1.5.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (2024.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (2.4.1)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (1.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (9.5.1.17)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (0.6.3)\nRequirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (2.26.2)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (1.11.1.6)\nRequirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (3.3.1)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch>=1.13.0->peft==0.11.1) (75.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (2025.4.26)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.11.1) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.11.1) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.41.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.41.2) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.41.2) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.41.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.41.2) (2024.2.0)\nDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: peft\n  Attempting uninstall: peft\n    Found existing installation: peft 0.14.0\n    Uninstalling peft-0.14.0:\n      Successfully uninstalled peft-0.14.0\nSuccessfully installed peft-0.11.1\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# import os\n# os.kill(os.getpid(), 9)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T09:04:17.858624Z","iopub.execute_input":"2025-07-07T09:04:17.858918Z","iopub.status.idle":"2025-07-07T09:04:17.863086Z","shell.execute_reply.started":"2025-07-07T09:04:17.858882Z","shell.execute_reply":"2025-07-07T09:04:17.862196Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torch\nfrom datasets import Dataset\nimport evaluate\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom sklearn.metrics import accuracy_score, f1_score  \nimport pandas as pd\nimport numpy as np\n","metadata":{"id":"vfNP0O6mDdYE","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T09:04:17.863935Z","iopub.execute_input":"2025-07-07T09:04:17.864187Z","iopub.status.idle":"2025-07-07T09:04:37.486676Z","shell.execute_reply.started":"2025-07-07T09:04:17.864164Z","shell.execute_reply":"2025-07-07T09:04:37.486120Z"}},"outputs":[{"name":"stderr","text":"2025-07-07 09:04:22.570662: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751879062.769367      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751879062.823190      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Update these paths with your actual dataset locations on Drive\ntrain_dataset_path ='data/AuthorshipStyleTransferTrain.xlsx'\nval_dataset_path =  'data/AuthorshipStyleTransferVal.xlsx'","metadata":{"id":"bzQpb7SADdYI","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T09:04:37.487436Z","iopub.execute_input":"2025-07-07T09:04:37.488076Z","iopub.status.idle":"2025-07-07T09:04:37.492340Z","shell.execute_reply.started":"2025-07-07T09:04:37.488056Z","shell.execute_reply":"2025-07-07T09:04:37.491499Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import sys\nimport os\n\nproject_root = os.getcwd()  # Should be /content/drive/MyDrive/AraGenEval2025\nif project_root not in sys.path:\n    sys.path.insert(0, project_root)\n\nprint(f\"Project root added to sys.path: {project_root}\")","metadata":{"id":"Do-3CdOID5G9","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T09:04:37.493120Z","iopub.execute_input":"2025-07-07T09:04:37.493467Z","iopub.status.idle":"2025-07-07T09:04:37.724784Z","shell.execute_reply.started":"2025-07-07T09:04:37.493439Z","shell.execute_reply":"2025-07-07T09:04:37.724116Z"}},"outputs":[{"name":"stdout","text":"Project root added to sys.path: /kaggle/working\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T09:04:37.726726Z","iopub.execute_input":"2025-07-07T09:04:37.726943Z","iopub.status.idle":"2025-07-07T09:04:37.889035Z","shell.execute_reply.started":"2025-07-07T09:04:37.726927Z","shell.execute_reply":"2025-07-07T09:04:37.888295Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from config import Config\n\nprint(Config.TRAIN_FILE)","metadata":{"id":"yiLsK5teEGAM","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T09:04:37.890097Z","iopub.execute_input":"2025-07-07T09:04:37.890783Z","iopub.status.idle":"2025-07-07T09:04:37.902685Z","shell.execute_reply.started":"2025-07-07T09:04:37.890756Z","shell.execute_reply":"2025-07-07T09:04:37.901866Z"}},"outputs":[{"name":"stdout","text":"data/AuthorshipStyleTransferTrain.xlsx\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")","metadata":{"id":"6llJHQ9cDdYH","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T09:04:37.903452Z","iopub.execute_input":"2025-07-07T09:04:37.903718Z","iopub.status.idle":"2025-07-07T09:04:37.908567Z","shell.execute_reply.started":"2025-07-07T09:04:37.903696Z","shell.execute_reply":"2025-07-07T09:04:37.907844Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport gc\n\ndef load_and_sample_dataset(\n    file_path,\n    sample_mode=\"all\",    # Options: \"all\", \"random\", \"stratified\"\n    sample_size=None,     # For \"random\"/\"stratified\": float (proportion) or int (absolute count)\n    random_state=42\n):\n    \"\"\"\n    Load dataset from Excel and apply sampling.\n\n    Args:\n        file_path (str): Path to dataset file.\n        sample_mode (str): \"all\", \"random\", or \"stratified\".\n        sample_size (float|int): Proportion (0-1) or count for sampling.\n        random_state (int): Random seed for reproducibility.\n\n    Returns:\n        pd.DataFrame: Sampled dataset.\n    \"\"\"\n    print(f\"📂 Loading dataset from: {file_path}\")\n    df = pd.read_excel(file_path, engine='openpyxl')\n\n    if sample_mode == \"all\":\n        sampled_df = df.copy()\n        print(f\"✅ Loaded full dataset with {len(sampled_df)} samples.\")\n\n    elif sample_mode == \"random\":\n        if sample_size is None:\n            raise ValueError(\"For 'random' mode, SAMPLE_SIZE must be set.\")\n        sampled_df = df.sample(\n            n=sample_size if isinstance(sample_size, int) else int(len(df) * sample_size),\n            random_state=random_state\n        )\n        print(f\"✅ Randomly sampled {len(sampled_df)} samples.\")\n\n    elif sample_mode == \"stratified\":\n        if sample_size is None or not (0 < sample_size < 1):\n            raise ValueError(\"For 'stratified' mode, SAMPLE_SIZE must be a proportion between 0 and 1.\")\n        sampled_df, _ = train_test_split(\n            df,\n            train_size=sample_size,\n            stratify=df['author'],\n            random_state=random_state\n        )\n        print(f\"✅ Stratified sampled {len(sampled_df)} samples (author distribution preserved).\")\n\n    else:\n        raise ValueError(f\"Invalid sample_mode: {sample_mode}\")\n\n    del df\n    gc.collect()\n\n    return sampled_df\n","metadata":{"id":"pxre7AjAEQP8","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T09:04:37.909276Z","iopub.execute_input":"2025-07-07T09:04:37.909517Z","iopub.status.idle":"2025-07-07T09:04:37.939838Z","shell.execute_reply.started":"2025-07-07T09:04:37.909492Z","shell.execute_reply":"2025-07-07T09:04:37.939096Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\n# model_name = \"megabot131/m-e5-large-toxic-classification-lora\"   # \"microsoft/Multilingual-MiniLM-L12-H384\" #\"CAMeL-Lab/bert-base-arabic-camelbert-ca\" \"aubmindlab/aragpt2-mega-detector-long\"\n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n# print(\"Max tokens:\", tokenizer.model_max_length)\n\n# model = AutoModelForSequenceClassification.from_pretrained(\n#     model_name,\n#     # num_labels=num_labels\n#     # remove use_safetensors=True\n# )\n# print(\"Model context limit:\", model.config.max_position_embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T09:04:37.940733Z","iopub.execute_input":"2025-07-07T09:04:37.941788Z","iopub.status.idle":"2025-07-07T09:04:37.948169Z","shell.execute_reply.started":"2025-07-07T09:04:37.941771Z","shell.execute_reply":"2025-07-07T09:04:37.947434Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"# === CONFIG ===\nSAMPLE_MODE = \"stratified\"  # \"all\", \"random\", \"stratified\"\nSAMPLE_SIZE = 0.1           # 10% for stratified or random. Set to None for full dataset.\n\n# === LOAD AND SAMPLE ===\ntrain_df = load_and_sample_dataset(\n    Config.TRAIN_FILE,\n    # sample_mode=SAMPLE_MODE,\n    # sample_size=SAMPLE_SIZE\n)\n\n# === LOAD AND SAMPLE ===\nval_df = load_and_sample_dataset(\n    Config.VAL_FILE,\n    # sample_mode=SAMPLE_MODE,\n    # sample_size=SAMPLE_SIZE\n)\n\nprint(\"Train shape:\", train_df.shape)\nprint(\"Validation shape:\", val_df.shape)\nprint(\"Authors in Train:\", train_df['author'].nunique())\nprint(\"Authors in Val:\", val_df['author'].nunique())\n\n# train_df.head()","metadata":{"id":"xNLnmQKpEVTM","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T09:04:37.948900Z","iopub.execute_input":"2025-07-07T09:04:37.949160Z","iopub.status.idle":"2025-07-07T09:04:45.713899Z","shell.execute_reply.started":"2025-07-07T09:04:37.949143Z","shell.execute_reply":"2025-07-07T09:04:45.713280Z"}},"outputs":[{"name":"stdout","text":"📂 Loading dataset from: data/AuthorshipStyleTransferTrain.xlsx\n✅ Loaded full dataset with 35122 samples.\n📂 Loading dataset from: data/AuthorshipStyleTransferVal.xlsx\n✅ Loaded full dataset with 4157 samples.\nTrain shape: (35122, 4)\nValidation shape: (4157, 4)\nAuthors in Train: 21\nAuthors in Val: 21\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"train_data = [{\"text\": row[\"text_in_author_style\"], \"label\": row[\"author\"]} for _, row in train_df.iterrows()]\nval_data = [{\"text\": row[\"text_in_author_style\"], \"label\": row[\"author\"]} for _, row in val_df.iterrows()]\n\nunique_authors = sorted(set(train_df[\"author\"]).union(set(val_df[\"author\"])))\nauthor2id = {author: idx for idx, author in enumerate(unique_authors)}\n\nfor item in train_data:\n    item[\"label\"] = author2id[item[\"label\"]]\nfor item in val_data:\n    item[\"label\"] = author2id[item[\"label\"]]\n\ntrain_dataset = Dataset.from_list(train_data)\nval_dataset = Dataset.from_list(val_data)","metadata":{"id":"VDsAHV1VDdYJ","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T09:10:18.289306Z","iopub.execute_input":"2025-07-07T09:10:18.289926Z","iopub.status.idle":"2025-07-07T09:10:21.747476Z","shell.execute_reply.started":"2025-07-07T09:10:18.289900Z","shell.execute_reply":"2025-07-07T09:10:21.746915Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import json\nwith open(\"/kaggle/working/evaluation/ar_style_classifier/results/author2id.json\", \"w\") as f:\n    json.dump(author2id, f, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T09:11:08.693356Z","iopub.execute_input":"2025-07-07T09:11:08.694120Z","iopub.status.idle":"2025-07-07T09:11:08.698261Z","shell.execute_reply.started":"2025-07-07T09:11:08.694094Z","shell.execute_reply":"2025-07-07T09:11:08.697638Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Tokenization","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nmodel_name = \"CAMeL-Lab/bert-base-arabic-camelbert-ca\" #\"allenai/longformer-base-4096\" #\"UBC-NLP/AraT5v2-base-1024\"\nnum_labels = len(unique_authors)\ntokenizer = AutoTokenizer.from_pretrained(model_name,use_safetensors=True)\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=num_labels,\n    # use_safetensors=True\n).to(device)\n\ndef preprocess_sliding(examples):\n    chunk_size = 512\n    stride = 256\n    input_ids_list = []\n    attention_mask_list = []\n    label_list = []\n    sample_id_list = []  # NEW\n\n    for idx, (text, label) in enumerate(zip(examples[\"text\"], examples[\"label\"])):\n        encodings = tokenizer(\n            text,\n            truncation=True,\n            max_length=chunk_size,\n            stride=stride,\n            return_overflowing_tokens=True,\n            return_attention_mask=True,\n        )\n        \n        num_chunks = len(encodings[\"input_ids\"])\n        for input_ids, attention_mask in zip(encodings[\"input_ids\"], encodings[\"attention_mask\"]):\n            input_ids_list.append(input_ids)\n            attention_mask_list.append(attention_mask)\n            label_list.append(label)\n            sample_id_list.append(idx)  # Use the index as sample identifier\n\n    return {\n        \"input_ids\": input_ids_list,\n        \"attention_mask\": attention_mask_list,\n        \"label\": label_list,\n        \"sample_id\": sample_id_list\n    }\n\n\ntrain_dataset = train_dataset.map(preprocess_sliding, batched=True, remove_columns=[\"text\"])\nval_dataset = val_dataset.map(preprocess_sliding, batched=True, remove_columns=[\"text\"])","metadata":{"id":"fBbSy6jBDdYK","trusted":true,"execution":{"iopub.status.busy":"2025-07-02T11:49:27.730103Z","iopub.execute_input":"2025-07-02T11:49:27.730330Z","iopub.status.idle":"2025-07-02T11:50:41.500128Z","shell.execute_reply.started":"2025-07-02T11:49:27.730314Z","shell.execute_reply":"2025-07-02T11:50:41.499420Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/86.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"652a05a1b2c347d79fc8be84d9f73433"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/468 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fe82f44c2894f3f98fd14008e3153fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04e6e2a7ce4340dd80722eb14a9e6371"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70cef8d04a7349a589755b3a1ff6ad53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd7c6e383c6c4cc7bcb212b0bf116466"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-ca and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/35122 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9a11f98c9cd4b5caca864acad57b3e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4157 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85e8e791929849399aa28cf08bdaaf93"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"print(train_dataset[0])\n","metadata":{"id":"n8rJEWfPUE52","trusted":true,"execution":{"iopub.status.busy":"2025-07-02T11:50:41.500915Z","iopub.execute_input":"2025-07-02T11:50:41.501189Z","iopub.status.idle":"2025-07-02T11:50:41.508099Z","shell.execute_reply.started":"2025-07-02T11:50:41.501162Z","shell.execute_reply":"2025-07-02T11:50:41.507295Z"}},"outputs":[{"name":"stdout","text":"{'label': 20, 'input_ids': [2, 2159, 5018, 2061, 1, 2837, 6201, 9887, 3153, 6, 1908, 3430, 3368, 4307, 21673, 6, 1912, 25237, 2038, 9993, 2731, 378, 1, 1, 1, 3720, 6045, 7475, 20317, 4335, 13987, 1, 1963, 7388, 2045, 2217, 1, 378, 2086, 1, 1, 26032, 1007, 6270, 1912, 2038, 3192, 30, 4910, 1, 1, 1908, 7933, 1014, 23613, 1013, 378, 1, 1, 2278, 7638, 1043, 29899, 1043, 380, 4053, 7110, 13991, 17, 5708, 2722, 7397, 2075, 20642, 2525, 4697, 6822, 24762, 7811, 7475, 16491, 12045, 1912, 7855, 378, 20471, 1, 2395, 2905, 9446, 12, 9377, 1, 1, 1, 1963, 15127, 8244, 7192, 26468, 1007, 13, 378, 1, 4423, 4884, 1979, 1, 8513, 1028, 1912, 2085, 6067, 6900, 378, 1, 378, 2086, 1, 1, 2794, 20585, 1028, 2743, 2734, 2379, 18, 28918, 13498, 1, 1972, 1, 23246, 6, 7931, 3552, 6, 378, 5632, 1911, 1, 2339, 12250, 8085, 1007, 17488, 10244, 18647, 378, 2073, 2103, 1, 6064, 11059, 2669, 378, 1, 11113, 3721, 1, 2574, 378, 2637, 1963, 16363, 1, 2813, 18, 1, 378, 2427, 23350, 2038, 3666, 1016, 4759, 11462, 2083, 378, 1, 11113, 3332, 2448, 3811, 8453, 6788, 2082, 1, 378, 2244, 22092, 20901, 1, 1979, 1, 2045, 6, 9722, 1043, 6, 1, 1908, 9506, 18, 8310, 12917, 2525, 1, 1979, 7811, 2061, 4602, 6822, 1913, 1, 6, 3760, 6327, 7855, 1912, 5788, 26299, 18341, 8431, 2420, 18, 18, 18, 6, 3760, 6327, 6, 10675, 6, 3727, 23794, 378, 3799, 12019, 1963, 1, 378, 6522, 1, 1979, 2652, 23361, 5267, 1, 378, 2086, 16983, 28796, 3041, 7560, 1904, 2061, 1, 2086, 8606, 1, 1908, 28477, 16833, 2298, 3157, 21454, 1912, 6913, 20884, 2434, 1007, 378, 2683, 2298, 3880, 3082, 378, 1, 1, 4058, 8661, 378, 2400, 20551, 1, 5, 3034, 2907, 4966, 1950, 2251, 11748, 2134, 4016, 1, 1961, 1, 6, 16854, 7999, 11993, 1033, 6, 2722, 30, 2244, 5942, 1, 1908, 9887, 5365, 3394, 5708, 30, 6, 1908, 3430, 3368, 4307, 21673, 6, 8968, 6967, 11623, 8454, 4307, 21673, 378, 1, 2498, 2692, 11623, 1908, 18364, 1009, 1972, 2461, 18, 2683, 4493, 1, 1979, 13376, 5179, 7522, 1, 10040, 378, 4017, 8254, 1922, 30, 6, 6967, 8454, 10440, 6, 378, 2843, 1912, 7355, 29189, 18, 6453, 1005, 2008, 1979, 6623, 378, 1972, 18760, 2251, 6242, 2045, 2085, 3259, 378, 2251, 1, 1912, 8200, 2045, 13293, 2377, 10355, 10423, 4820, 1922, 378, 1972, 1, 2538, 5101, 6, 1908, 3430, 12525, 1013, 6, 2139, 4083, 3044, 1908, 11058, 2043, 1, 1908, 2456, 2095, 2075, 9273, 1912, 10133, 2488, 378, 2061, 1, 11058, 1, 1, 1, 378, 4976, 1, 6967, 11623, 2075, 7892, 2075, 18868, 2075, 29189, 18, 3], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'sample_id': 0}\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"# # Load metrics\n# metric_acc = evaluate.load(\"accuracy\")\n# metric_f1 = evaluate.load(\"f1\")\n\n\n# def compute_metrics(p):\n#     preds = np.argmax(p.predictions, axis=1)\n#     acc = metric_acc.compute(predictions=preds, references=p.label_ids)[\"accuracy\"]\n#     f1 = metric_f1.compute(predictions=preds, references=p.label_ids)[\"f1\"]\n#     return {\"accuracy\": acc, \"f1\": f1}\n\n\n\nimport numpy as np\nimport evaluate\n\n# Load metrics\nmetric_acc = evaluate.load(\"accuracy\")\nmetric_f1 = evaluate.load(\"f1\")\n\n# Sanity check for labels\nEXPECTED_NUM_CLASSES = len(unique_authors)  # make sure this is defined correctly\n\n\ndef compute_metrics(p):\n    preds = np.argmax(p.predictions, axis=1)\n\n    # Defensive check: Are labels within expected range?\n    if np.max(preds) >= EXPECTED_NUM_CLASSES or np.min(preds) < 0:\n        raise ValueError(f\"Predictions contain invalid class indices: {np.unique(preds)}\")\n\n    if np.max(p.label_ids) >= EXPECTED_NUM_CLASSES or np.min(p.label_ids) < 0:\n        raise ValueError(f\"Label IDs contain invalid class indices: {np.unique(p.label_ids)}\")\n\n    acc = metric_acc.compute(predictions=preds, references=p.label_ids)[\"accuracy\"]\n    \n    # Use macro average for multiclass tasks\n    f1 = metric_f1.compute(predictions=preds, references=p.label_ids, average=\"macro\")[\"f1\"]\n    \n    return {\"accuracy\": acc, \"f1\": f1}\n\n","metadata":{"id":"igmtb3z6DdYM","trusted":true,"execution":{"iopub.status.busy":"2025-07-02T13:17:16.469310Z","iopub.execute_input":"2025-07-02T13:17:16.469952Z","iopub.status.idle":"2025-07-02T13:17:16.982302Z","shell.execute_reply.started":"2025-07-02T13:17:16.469926Z","shell.execute_reply":"2025-07-02T13:17:16.981468Z"}},"outputs":[],"execution_count":61},{"cell_type":"markdown","source":"## Training Setup","metadata":{}},{"cell_type":"code","source":"# Dummy sanity check\ndummy_preds = np.random.randint(0, EXPECTED_NUM_CLASSES, size=100)\ndummy_labels = np.random.randint(0, EXPECTED_NUM_CLASSES, size=100)\n\ntest_acc = metric_acc.compute(predictions=dummy_preds, references=dummy_labels)[\"accuracy\"]\ntest_f1 = metric_f1.compute(predictions=dummy_preds, references=dummy_labels, average=\"macro\")[\"f1\"]\n\nprint(f\"Sanity metric test - Accuracy: {test_acc:.4f}, F1 (macro): {test_f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T13:17:21.749686Z","iopub.execute_input":"2025-07-02T13:17:21.749988Z","iopub.status.idle":"2025-07-02T13:17:22.784341Z","shell.execute_reply.started":"2025-07-02T13:17:21.749964Z","shell.execute_reply":"2025-07-02T13:17:22.783447Z"}},"outputs":[{"name":"stdout","text":"Sanity metric test - Accuracy: 0.0400, F1 (macro): 0.0351\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"print(len(train_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T13:17:28.950712Z","iopub.execute_input":"2025-07-02T13:17:28.951019Z","iopub.status.idle":"2025-07-02T13:17:28.955582Z","shell.execute_reply.started":"2025-07-02T13:17:28.950997Z","shell.execute_reply":"2025-07-02T13:17:28.954649Z"}},"outputs":[{"name":"stdout","text":"43507\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"import os\nos.cpu_count()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T13:18:36.022645Z","iopub.execute_input":"2025-07-02T13:18:36.023207Z","iopub.status.idle":"2025-07-02T13:18:36.028677Z","shell.execute_reply.started":"2025-07-02T13:18:36.023180Z","shell.execute_reply":"2025-07-02T13:18:36.027862Z"}},"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\n## batch size calculation\neffective_batch_size = 32\nbatch_size = 16\naccumulation_steps = effective_batch_size // batch_size\nepochs = 5\nOUTPUT_DIR=\"evaluation/ar_style_classifier/\"\n\n#config training env\nmodel.gradient_checkpointing_disable()\nimport os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n# os.environ[\"WANDB_DISABLED\"] = \"true\"\n\n\n\n# args\ntraining_args = TrainingArguments(\n    output_dir=\"evaluation/ar_style_classifier/\",\n    max_steps=-1,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    # save_steps=500,\n    # eval_steps=1000,\n    # eval_strategy=\"steps\",\n    # save_strategy=\"steps\",\n    # save_steps=10,\n    # eval_steps=10,  # ⬅️ super frequent eval for debugging\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=epochs,\n    gradient_accumulation_steps=accumulation_steps,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1\",\n    save_total_limit=2,\n    logging_steps=accumulation_steps,\n    logging_strategy=\"steps\",\n    dataloader_num_workers=0,\n    report_to=\"none\"\n)","metadata":{"id":"eDc-9AQiDdYN","trusted":true,"execution":{"iopub.status.busy":"2025-07-02T13:23:44.562133Z","iopub.execute_input":"2025-07-02T13:23:44.562684Z","iopub.status.idle":"2025-07-02T13:23:44.595694Z","shell.execute_reply.started":"2025-07-02T13:23:44.562660Z","shell.execute_reply":"2025-07-02T13:23:44.594995Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\nfrom transformers import Trainer, TrainingArguments, DefaultDataCollator\n\nfrom transformers import DataCollatorWithPadding\ndata_collator = DataCollatorWithPadding(tokenizer)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    data_collator=data_collator,\n    callbacks=[],  # Completely remove default callbacks like WandB\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n)\n\nprint(f\"Train dataset size: {len(train_dataset)}\")\nprint(f\"Eval dataset size: {len(val_dataset)}\")","metadata":{"id":"Xc44ADNWDdYO","trusted":true,"execution":{"iopub.status.busy":"2025-07-02T13:23:48.764197Z","iopub.execute_input":"2025-07-02T13:23:48.764812Z","iopub.status.idle":"2025-07-02T13:23:48.779005Z","shell.execute_reply.started":"2025-07-02T13:23:48.764788Z","shell.execute_reply":"2025-07-02T13:23:48.778286Z"}},"outputs":[{"name":"stdout","text":"Train dataset size: 43507\nEval dataset size: 5031\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"import torch\nimport gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"id":"2w7G7WiWgiY0","trusted":true,"execution":{"iopub.status.busy":"2025-07-02T13:23:52.102054Z","iopub.execute_input":"2025-07-02T13:23:52.102362Z","iopub.status.idle":"2025-07-02T13:23:52.810293Z","shell.execute_reply.started":"2025-07-02T13:23:52.102340Z","shell.execute_reply":"2025-07-02T13:23:52.809528Z"}},"outputs":[],"execution_count":73},{"cell_type":"markdown","source":"## Launch Training","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\nimport time\nimport os\nfrom config import Config\n\n\nprint(f\"📢 Starting training at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n\nstart_time = time.time()\n\n# Detect checkpoint\nlast_checkpoint = None\nCHECKPOINT_DIR = OUTPUT_DIR    #os.path.join(Config.MODEL_WEIGHTS_FOLDER,safe_model_name(MODEL_CONFIG[\"name\"]))\nRESUME_TRAINING=False\n\nif RESUME_TRAINING:\n    if os.path.isdir(CHECKPOINT_DIR):\n        checkpoints = [d for d in os.listdir(CHECKPOINT_DIR) if d.startswith(\"checkpoint-\")]\n\n        if checkpoints:\n            # Sort numerically based on step number\n            latest_checkpoint =  max(checkpoints, key=lambda x: int(x.split(\"-\")[-1]))\n            last_checkpoint = os.path.join(CHECKPOINT_DIR, latest_checkpoint)\n            print(f\"✅ Found checkpoint at {last_checkpoint}. Will resume training from there.\")\n        else:\n            print(\"⚠️ No checkpoints found. Starting from scratch.\")\n    else:\n        print(\"⚠️ Checkpoint directory doesn't exist. Starting from scratch.\")\nelse:\n    print(\"🆕 Starting fresh training (no checkpoint resume).\")\n\n# Start training\ntry:\n    if last_checkpoint:\n        train_output = trainer.train(\n            resume_from_checkpoint=last_checkpoint,\n            # ignore_keys_for_eval=[\"optimizer\", \"scheduler\"]\n        )\n    else:\n        train_output = trainer.train()\n\n    total_time = time.time() - start_time\n    print(f\"✅ Training completed in {total_time/3600:.2f} hours\")\n\n    if train_output.metrics:\n        print(\"\\n📊 Final Training Metrics:\")\n        for key, value in train_output.metrics.items():\n            print(f\" {key}: {value:.4f}\")\n\nexcept KeyboardInterrupt:\n    print(\"\\n⚠️ Training interrupted by user. Saving checkpoint...\")\n    interrupted_path = os.path.join(CHECKPOINT_DIR, \"checkpoint-interrupted\")\n    trainer.save_model(interrupted_path)\n    print(f\"💾 Checkpoint saved at {interrupted_path}\")","metadata":{"id":"VAhhNrNhDdYP","trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-07-02T13:24:00.520857Z","iopub.execute_input":"2025-07-02T13:24:00.521381Z"}},"outputs":[{"name":"stdout","text":"📢 Starting training at 2025-07-02 13:24:00\n🆕 Starting fresh training (no checkpoint resume).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4081' max='6800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4081/6800 2:20:42 < 1:33:47, 0.48 it/s, Epoch 3/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.009800</td>\n      <td>0.775574</td>\n      <td>0.832240</td>\n      <td>0.789812</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000700</td>\n      <td>0.693766</td>\n      <td>0.861459</td>\n      <td>0.813936</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.047600</td>\n      <td>0.820671</td>\n      <td>0.857682</td>\n      <td>0.797888</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"## Save Results","metadata":{}},{"cell_type":"code","source":"output_dir = \"evaluation/ar_style_classifier/results\"\nmodel.save_pretrained(output_dir)\ntokenizer.save_pretrained(output_dir)\nprint(f\"Model saved to {output_dir}\")","metadata":{"id":"UoVDOv3kDdYP","trusted":true,"execution":{"iopub.status.busy":"2025-07-02T12:21:34.468184Z","iopub.status.idle":"2025-07-02T12:21:34.468426Z","shell.execute_reply.started":"2025-07-02T12:21:34.468311Z","shell.execute_reply":"2025-07-02T12:21:34.468321Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"# # --- Inference on full validation texts ---\n# def predict_full_text(text):\n#     enc = tokenizer(\n#         text,\n#         truncation=True,\n#         padding=\"max_length\",\n#         max_length=512,\n#         stride=256,\n#         return_overflowing_tokens=True,\n#         return_tensors=\"pt\"\n#     ).to(device)\n#     logits = model(**enc).logits  # [num_chunks, num_labels]\n#     avg_logits = logits.mean(dim=0)\n#     probs = torch.softmax(avg_logits, dim=0)\n#     return torch.argmax(probs).item(), probs.cpu().tolist()\n\n# # --- Evaluate across validation set ---\n# preds, refs = [], []\n# for example in val_df.itertuples():\n#     pred, _ = predict_full_text(example.text_in_author_style)\n#     preds.append(pred)\n#     refs.append(author2id[example.author])\n\n# from sklearn.metrics import accuracy_score, f1_score\n# print(\"Validation Accuracy:\", accuracy_score(refs, preds))\n# print(\"Validation F1‑macro:\", f1_score(refs, preds, average=\"macro\"))\n\n","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-07-02T12:21:34.492093Z","iopub.execute_input":"2025-07-02T12:21:34.492736Z","iopub.status.idle":"2025-07-02T12:21:34.496765Z","shell.execute_reply.started":"2025-07-02T12:21:34.492712Z","shell.execute_reply":"2025-07-02T12:21:34.496039Z"}},"outputs":[],"execution_count":51}]}